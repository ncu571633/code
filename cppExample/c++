
***************************************************************************************************************
virtual table: contains an entry for each virtual function
entries in the vtable can point to most derived functions
vtables exist at the class level, meaning one vtable per class, and is shared by all instances.

steps:
    vpointer find vtable
    vtable[function name] find correct function address
      
    Get the vtable pointer, which points to an array of function pointers (function addresses), one for each virtual function, from the object.
    Get the right function address from the vtable into a register (the index where the correct function address is stored is decided at compile-time).
    Jump to the address in that register, rather than jumping to a hardcoded address.

slow:
    compiler can't know which function to call, can't inline it or perform optimization (preparing registers, calling, restoring state afterwards).
    cache and branch predictor can't help. no perfectly predictable branch. 

function call steps:
    Copy some registers on the stack, to allow the called function to use those registers.
    Copy the arguments into predefined locations, so that the called function can find them regardless from where it is called.
    Push the return address.
    Branch/jump to the function's code, which is a compile-time address and hence hardcoded in the binary by the compiler/linker.
    Get the return value from a predefined location and restore registers we want to use.

Virtual Destructor: used to free the memory of the derived class object, by using the base class's pointer object

No virtual destructor for base class: 
    Deleting an object of a derived class using a pointer of the parent class shows an undefined behavior

Implementation
When the compiler generates the code for the destructor, it adds extra code both before and after the user defined code. 

    modify vptr to refer to the vtable of derived
    user code
    calls to the member destructors and base destructor(s) this->~mybase()

`delete`ing base classes with non-virtual destructors
    undefined 

https://stackoverflow.com/questions/32132058/what-do-clang-and-gcc-do-when-deleteing-base-classes-with-non-virtual-destruct/37738132#37738132

Take that address of that first base class object, do roughly the equivalent of a reinterpret_cast on it, and try to use that memory as if it were an object of the base class specified by the pointer (e.g., base2). For example, let's assume base2 has a pointer at offset 14, and base2's destructor attempts to delete a block of memory it points at. With a non-virtual destructor, it'll probably receive a pointer to the base1 subject--but it'll still look at offset 14 from there, and try to treat that as a pointer, and pass it to delete. It could be that base1 contains a pointer at that offset, and it's actually pointing at some dynamically allocated memory, in which case this might actually appear to succeed. Then again, it could also be that it's something entirely different, and the program dies with an error message about (for example) attempting to free an invalid pointer.

    #include <iostream>
    #include <string>
    #include <vector>
    
    class base{ 
        char *data;
        std::string s;
        std::vector<int> v;
    public:
        base() { data = new char;  v.push_back(1); s.push_back('a'); }
        ~base() { std::cout << "~base\n"; delete data; }
    };
    
    class base2 {
        char *data2;
    public:
        base2() : data2(new char) {}
        ~base2() { std::cout << "~base2\n"; delete data2; }
    };
    
    class derived : public base, public base2 { 
        char *more_data;
    
    public:
        derived() : more_data(new char) {}
        ~derived() { std::cout << "~derived\n"; delete more_data; }
    };
    
    int main() {
        base2 *b = new derived;
        delete b;
    }

***************************************************************************************************************

volatile: ask the compiler not to optimization for this variable
optimization (of some parts of your program) may be undesirable, because it may be that someone else is changing the value of some_int from outside the program which compiler is not aware of

    

stack unwinding:


vector initialization
class broad
{
    public:
        broad(int m, int n)
        : m(m, vector<int>(n, 1))
        {
            
        }

    private:
        vector<vector<int>> m;
    
};


int main()
{
    int a=5, b=0;
    int &r = a;
    r = b++;
    cout<<a<<r<<b;   //001

    return 0;
}

     struct A{
         ~A()
         {
             cout<< "~A";
         }
     };
     
     struct B: public A
     {
         virtual ~B()
         {
             cout<< "~B";
         }
     };
     
int main()
{


    A*a = new B();    // ~A
    delete a;
    return 0;
}

     struct A{
         virtual void print(int x = 1)
         {
             cout<< "A" << x;
         }
     };
     
     struct B: public A
     {
          virtual void print(int x = 2)
         {
             cout<< "B" << x;
         }
     };
     
int main()
{
    A*a = new B;
    a->print();
    return 0;
}

B1


What are pointer and reference? 
1. A pointer can be re-assigned any number of times while a reference can not be reassigned after initialization. 
Once defined, a reference cannot be reassigned because it is an alias to its target.
2. A pointer can point to NULL while reference can never point to NULL 
3. You can't take the address of a reference like you can with pointers. 
That is because a reference is not an object, it is an alias (this means it is another name for an object).
4. There's no "reference arithmetics" (but you can take the address of an object pointed by a reference and do pointer arithmetics on it as in &obj + 5). 

Give an example of when you must use a reference instead of a pointer?
Copy constructor


The difference between vector and deque(Double-ended queues)
One main difference between vectors and deques is that the latter allows efficient insertion at the front of the structure as well as the back.
Deques also do not guarantee that their elements are contiguous in memory so the at-style operator (indexing) may not be as efficient.

A deque is somewhat recursively defined: internally it maintains a double-ended queue of chunks (“blocks” in the graphic below) of fixed size. Each chunk is a vector, and the queue (“map” in the graphic below) of chunks itself is also a vector.


placement new
The simplest use is to place an object at a particular location in memory. This is done by supplying the place as a pointer parameter to the new part of a new expression
void someCode()
{
  char memory[sizeof(Fred)];     // Line #1
  void* place = memory;          // Line #2

  Fred* f = new(place) Fred();   // Line #3 (see "DANGER" below)
  // The pointers f and place will be equal

  ...
}

Order of Constructor/ Destructor Call in C++
 base class is called first to initialize all the inherited members.



lvalue, rvalue
An lvalue refers to an object that persists beyond a single expression. You can think of an lvalue as an object that has a name.
An rvalue is a temporary value that does not persist beyond the expression that uses it.
int x = 3 + 4;
In this example, x is an lvalue because it persists beyond the expression that defines it. The expression 3 + 4 is an rvalue because it evaluates to a temporary value that does not persist beyond the expression that defines it.

Unique pointer
A unique_ptr does not share its pointer. It cannot be copied to another unique_ptr, passed by value to a function, or used in any C++ Standard Library algorithm that requires copies to be made.
  std::unique_ptr<int> u3 (new int);

  The shared_ptr type is a smart pointer in the C++ standard library that is designed for scenarios in which more than one owner might have to manage the lifetime of the object in memory. After you initialize a shared_ptr you can copy it, pass it by value in function arguments, and assign it to other shared_ptr instances. All the instances point to the same object


Stack unwinding:
As you create objects statically (on the stack as opposed to allocating them in the heap memory) and perform function calls, they are "stacked up".

When a scope (anything delimited by { and }) is exited (by using return XXX;, reaching the end of the scope or throwing an exception) everything within that scope is destroyed (destructors are called for everything). This process of destroying local objects and calling destructors is called stack unwinding.

avoiding memory leaks (anything dynamically allocated that is not managed by a local object and cleaned up in the destructor will be leaked) 
the C++ specifications state that you should never throw an exception before any existing exception has been handled. This means that the stack unwinding process should never throw an exception


Exception safety guarantees, guidelines that class library implementers and clients can use when reasoning about exception handling safety in any programming language that uses exceptions, particularly C++.
no-leak guarantee



Memory management
static variable: 



The OFFSETOF() macro
#define OFFSETOF(TYPE, ELEMENT) ((size_t)&(((TYPE *)0)->ELEMENT))

#include <stdio.h>
 
#define OFFSETOF(TYPE, ELEMENT) ((size_t)&(((TYPE *)0)->ELEMENT))
 
typedef struct PodTag
{
   int     i;
   double  d;
   char    c;
} PodType;
 
int main()
{
   printf("%d", OFFSETOF(PodType, c) );
    virtual table: contains an entry for each virtual function
entries in the vtable can point to most derived functions
vtables exist at the class level, meaning one vtable per class, and is shared by all instances.

steps:
    vpointer find vtable
    vtable[function name] find correct function address
      
    Get the vtable pointer, which points to an array of function pointers (function addresses), one for each virtual function, from the object.
    Get the right function address from the vtable into a register (the index where the correct function address is stored is decided at compile-time).
    Jump to the address in that register, rather than jumping to a hardcoded address.


slow:
    compiler can't know which function to call, can't inline it or perform optimization (preparing registers, calling, restoring state afterwards).
    cache and branch predictor can't help. no perfectly predictable branch. 


function call steps:
    Copy some registers on the stack, to allow the called function to use those registers.
    Copy the arguments into predefined locations, so that the called function can find them regardless from where it is called.
    Push the return address.
    Branch/jump to the function's code, which is a compile-time address and hence hardcoded in the binary by the compiler/linker.
    Get the return value from a predefined location and restore registers we want to use.




Virtual Destructor: used to free the memory of the derived class object, by using the base class's pointer object

No virtual destructor for base class: 
    Deleting an object of a derived class using a pointer of the parent class shows an undefined behavior

Implementation
When the compiler generates the code for the destructor, it adds extra code both before and after the user defined code. 

    modify vptr to refer to the vtable of derived
    user code
    calls to the member destructors and base destructor(s) this->~mybase()
    


   getchar();
   return 0;
}

((size_t)&(((PodType *)0)->c))
Since we are considering 0 as address of the structure variable, c will be placed after 16 bytes of its base address i.e. 0x00 + 0x10. Applying & on the structure element (in this case it is c) returns the address of the element which is 0x10. Casting the address to unsigned int (size_t) results in number of bytes the element is placed in the structure.


aligned malloc implementation

void* aligned_malloc(size_t required_bytes, size_t alignment)
{
    void* p1; // original block
    void** p2; // aligned block
    int offset = alignment - 1 + sizeof(void*);
    if ((p1 = (void*)malloc(required_bytes + offset)) == NULL)
    {
       return NULL;
    }
    p2 = (void**)(((size_t)(p1) + offset) & ~(alignment - 1));
    p2[-1] = p1;
    return p2;
}

void aligned_free(void *p)
{
    free(((void**)p)[-1]);
}

void main (int argc, char *argv[])
{
    char **endptr;
    int *p = aligned_malloc (100, strtol(argv[1], endptr, 10));

    printf ("%s: %p\n", argv[1], p);
    aligned_free (p);
}

    You need an offset if you want to support alignments beyond what your system's malloc() does. For example if your system malloc() aligns to 8 byte boundaries, and you want to align to 16 bytes, you ask for 15 bytes extra so you know for sure you can shift the result around to align it as requested. You also add sizeof(void*) to the size you pass to malloc() to leave room for bookkeeping.

    ~(alignment - 1) is what guarantees the alignment. For example if alignment is 16, then subtract 1 to get 15, aka 0xF, then negating it makes 0xFF..FF0 which is the mask you need to satisfy the alignment for any returned pointer from malloc(). Note that this trick assumes alignment is a power of 2 (which practically it normally would be, but there really should be a check).

    It's a void**. The function returns void*. This is OK because a pointer to void is "A pointer to any type," and in this case that type is void*. In other words, converting void* to and from other pointer types is allowed, and a double-pointer is still a pointer.

    The overall scheme here is to store the original pointer before the one that's returned to the caller. Some implementations of standard malloc() do the same thing: stash bookkeeping information before the returned block. This makes it easy to know how much space to reclaim when free() is called.


Processes are managed by the kernel. The kernel doesn't care how the programmer allocates variables. All it knows is that certain blocks of memory belong to the process. The C runtime matches C memory management features to kernel features: automatic variables go into a memory block called “stack” and dynamic storage (malloc and friends) go into a memory block called “heap”. The process calls system calls such as sbrk and mmap to obtain memory with a granularity of MMU pages. Inside those blocks, the runtime determines where to put automatic varibles and dynamically allocated objects.

When a process dies, the kernel updates its memory management table to record, for each MMU page, that it is no longer in use by the process. This takes place no matter how the process exits, whether of its own violition (by calling a system call) or not (killed by a signal). Pages that are no longer used by any process are marked as reusable.

It's generally good hygiene to free the dynamically allocated storage that you're no longer using, because you never know when a piece of code might be reused in a long-running program. But when a process dies, the operating system will release all of its resources: memory, open file, etc.
