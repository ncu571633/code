https://github.com/donnemartin/system-design-primer

Push vs Pull 

Push: when a client requests work from a server — the work is “pushed” to the server
Push Disadvantages
load balancing
a push system is you need to know where to send your request: DNS


Pull: when the server requests work, usually not directly from the client. The most common approach here is when there is some kind of work queue that clients enqueue messages on, and the server pulls messages from that queue. 
Pull Advantages
The biggest advantage of pull systems is that they distribute work to those that can process it

Pull Disadvantages
The biggest problem with pull systems is probably when you have a request/response communication pattern. It is easy enough to send the request, but how do you get the response



https://www.lecloud.net/post/7295452622/scalability-for-dummies-part-1-clones
Scalability for Dummies - Part 1: Clones
Public servers of a scalable web service are hidden behind a load balancer.

first golden rule for scalability
1. every server contains exactly the same codebase and does not store any user-related data, like sessions or profile pictures, on local disc or memory. 
Sessions need to be stored in a centralized data store which is accessible to all your application servers. It can be an external database or an external persistent cache, like Redis
An external persistent cache will have better performance than an external database
a code change is sent to all your servers without one server still serving old code

Scalability for Dummies - Part 2: Database
SQL databases are vertically scalable, NoSQL databases are horizontally scalable.
In most situations, SQL databases are vertically scalable, which means that you can increase the load on a single server by increasing things like CPU, RAM or SSD. NoSQL databases, on the other hand, are horizontally scalable. This means that you handle more traffic by sharding, or adding more servers in your NoSQL database

think about what happens if you need to lock two tables for an atomic transaction, and they are on different servers

Database shard, is a horizontal partition of data in a database or search engine. rows of a database table are held separately
Horizontal partitioning involves putting different rows into different tables
Vertical partitioning involves creating tables with fewer columns and using additional tables to store the remaining columns

Scalability for Dummies - Part 3: Cache
A cache is a simple key-value store and it should reside as a buffering layer between your application and your data storage. 
There are 2 patterns of caching your data
  #1 - Cached Database Queries: Whenever you do a query to your database, you store the result dataset in cache. 
  A hashed version of your query is the cache key. 
  The next time you run the query, you first check if it is already in the cache. 
  The next time you run the query, you check at first the cache if there is already a result. 
  This pattern has several issues. The main issue is the expiration. It is hard to delete a cached result when you cache a complex query (who has not?). When one piece of data changes (for example a table cell) you need to delete all cached queries who may include that table cell. You get the point?

  #2 - Cached Objects
In general, see your data as an object like you already do in your code (classes, instances, etc.). Let your class assemble a dataset from your database and then store the complete instance of the class or the assembed dataset in the cache. 
You have, for example, a class called “Product” which has a property called “data”. It is an array containing prices, texts, pictures, and customer reviews of your product. The property “data” is filled by several methods in the class doing several database requests which are hard to cache, since many things relate to each other. N
ow, do the following: when your class has finished the “assembling” of the data array, directly store the data array, or better yet the complete instance of the class, in the cache! This allows you to easily get rid of the object whenever something did change and makes the overall operation of your code faster and more logical.

And the best part: it makes asynchronous processing possible! Just imagine an army of worker servers who assemble your objects for you! The application just consumes the latest cached object and nearly never touches the databases anymore!

Some ideas of objects to cache:
    user sessions (never use the database!)
    fully rendered blog articles
    activity streams
    user<->friend relationships 

  
Memcached (mem-cash-dee) is a distributed memory-caching system. 
It is often used to speed up dynamic database-driven websites by caching data and objects in RAM to reduce the number of times an external data source (such as a database or API) must be read
The system uses a client–server architecture. 
    The servers maintain a key–value associative array; the clients populate this array and query it by key. 
    If a client wishes to set or read the value corresponding to a certain key, the client's library first computes a hash of the key to determine which server to use. This gives a simple form of sharding and scalable shared-nothing architecture across the servers. 
    The server computes a second hash of the key to determine where to store or read the corresponding value. The servers keep the values in RAM; 
    if a server runs out of RAM, it discards the oldest values. 


    A cab booking service was discussed.
    the discussion included a lot of discussion on Driver and customer matching service, map service, and load balancing.
    also included discussion on the type of connections (web-socket or Long poll)
    A discussion on scale and numbers, type of DB, and why that DB was chosen apart from other DBs took place.
    Schema was discussed as well.
    this interview plays a huge role in levelling so talk and drive this to your benefit.


1. Database design
  (1)Memory: a hash table
        Compress your data
        store reference instead of the actual data
        using different data representations like bit array (integer) or vectors
  
  (2)relational database: relationship between tables:
      SQL databases uses SQL ( structured query language ) for defining and manipulating the data, which is very powerful. 
      In NoSQL database, queries are focused on collection of documents. 
      For complex queries: SQL databases are good fit for the complex query intensive environment whereas NoSQL databases are not good fit for complex queries. 

      Scalable:
          SQL databases are vertically scalable whereas the NoSQL databases are horizontally scalable. 

      Standard schema:
            SQL databases have predefined schema whereas NoSQL databases have dynamic schema for unstructured data.
            SQL databases are table based databases whereas NoSQL databases are document based, key-value pairs.
            This means that SQL databases represent data in form of tables which consists of n number of rows of data whereas NoSQL databases are the collection of key-value pair,
          documents, graph databases or wide-column stores which do not have standard schema definitions which it needs to adhered to.


2. Scale architecture  replica
    divide the whole system into small components
    database separate from web apps --- different computers

  (1) vertical splitting (partitioning): splitting the database into sub-databases like user database, comment database
  (2) horizontal splitting: US users, European users

    Static Data:
    Image optimization: to save space, images should be compressed
    large static files
    Imagine that each video has thumbnails of different sizes for different screens

    CDN (Content delivery network). multiple data centers
    3rd party network: CDN replicates content in multiple places
    closer to the user

    long-tailed, which are videos have only 1-20 views a day.
    One straightforward approach is to host popular videos in CDN and less popular videos are stored in our own servers by location

    Popular videos are viewed by a huge number of audiences in different locations


3. load-balancer
    (1) Round Robin:
     • The first request is sent to Server A.
    • The second request is sent to Server B.
    • The third request is sent to Server C.

     (2) Weighted Load Balancing
    • Server A can handle 15 requests per second, on average
    • Server B can handle 10 requests per second, on average
    • Server C can handle 5 requests per second, on average

    Next, assume that the load balancer receives 6 requests.

    • 3 requests are sent to Server A
    • 2 requests are sent to Server B
    • 1 request is sent to Server C.


    A load balancer that keeps sticky sessions will create a unique session object for each client. 
    For each request from the same client, the load balancer processes the request to the same web server each time,
    where data is stored and updated as long as the session exists. 


4. System availability
    suppose one of our machines crashes for some reason
    The most common solution is replica
    By setting machines with duplicate resources, we can significantly reduce the system downtime


5. Machine learning
    (1)Feed ranking: 
    one costly operation is to render users feed
    The server has to go over everyone the user follows, fetch all the pictures from them, and rank them based on particular algorithms

    read the top N most recent pictures
    offline pipelines to precompute some signals that can speed up the ranking.

    rank everything in chronological order
    an algorithm that combines time and how likely the user will like this picture
    like/comment numbers, whether the user has liked many photos of the owner and so on

    (2) machine learning - recommendation system
    Explicit features: ratings, favorites
    Implicit features: If a user has watched a video for only a couple of seconds, probably it’s a negative sign
    Offline: similiar videos 
    Online: user profile and his actions
    if user A and B have watched a bunch of same videos, it’s highly likely that user A will like videos liked by B. 


6. Concurrency
    (1)The common solution of course is using a let’s say there’s only one book left in the store and two people buy it simultaneously
    add lock

    Optimistic concurrency control 
    before committing changes, each transaction should check if the data has the same state as it did when you last read itlock
    split the cache into multiple shards and have a lock for each of them
    given that hot entries are more likely to be visited, certain shards will be more often locked than others.

    First approach is to keep a local copy in coordinator. Whenever updating a resource, the coordinator will keep the copy of updated version. So in case the update fails, the coordinator is able to re-do the operation.

    (2)resolve conflict in read. Suppose when the requested resource locates in A1, A2 and A3, the coordinator can ask from all three machines. If by any chance the data is different, the system can resolve the conflict on the fly.

    (3)use commit logs. To update the cache, we can store all the mutations into logs rather than update immediately. And then some background processes will execute all the logs asynchronously

    (4) Strong consistency
    One approach is to force all updates to happen in the same order atomically. 
    Weak consistency

    Another extreme case is that we can provide minimum curation. Every replica will see every update, however, they may be in different orders

    Dynamo 


7. Security
    (1)How to detect fake users?
    identify several related features like registration date, the number of followers, the number of feeds etc. and build a machine learning system to detect if a user is fake.

    (2) particular IP issues too many requests





